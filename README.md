# Aerial Target Detection and Tracking ğŸ¯ğŸ“·

This repository contains Python code for real-time **detection** and **tracking** 
of aerial targets (currently rc planes) 
using camera-based computer vision. 
The system is built using **YOLOv8** for object detection 
and **OpenCV** for tracking and visualization.

<img title="a title" alt="Alt text" src="./doc/rc_plane_detection.png">


## ğŸš€ Features

- âœ… Real-time object detection using YOLOv8 (Ultralytics)
- ğŸ¯ Multi-object tracking with OpenCV or DeepSORT (not implemented yet!)
- ğŸ§  Easy integration with custom-trained detection models
- ğŸ’¾ Option to save tracking logs and video output

## ğŸ“ Project Structure

```text
aerial-tracking/
â”œâ”€â”€ detection/           # Code related to YOLOv8 detection
â”‚   â””â”€â”€ detector.py
â”œâ”€â”€ tracking/            # Tracking algorithms (e.g., OpenCV, DeepSORT)
â”‚   â””â”€â”€ tracker.py
â”œâ”€â”€ dataset_utils/            # Utility functions for handling dataset for training
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ test_utils/               # Utility functions (grabbing, drawing, logging, etc.)
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ detector_tracker_record_test.py    # Main entry point for detection + tracking
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Installation


### ğŸ“¦ Dependencies

- [Ultralytics YOLOv8](https://docs.ultralytics.com/)
- [OpenCV](https://opencv.org/)
- [NumPy](https://numpy.org/)
- PyYAML for config loading

All dependencies are listed in \`requirements.txt\`.


### Setup

1. Clone the repository:

```bash
git clone https://github.com/yourusername/aerial-tracking.git
cd aerial-tracking
```

2. Set up a virtual environment (optional but recommended):

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

3. Install the required packages:

```bash
pip install -r requirements.txt
```

### ğŸ§  Neural Network Model Setup

We currently use an [ultralytics-YOLOv8n](https://github.com/ultralytics/ultralytics) that has been transfer-learned with our own rc-plane images dataset.
The model parameter files are currently stored as github release assets.

The models should be downloaded from github release along with the corresponding version of the code.

Alternatively the `model_path` parameter can point to any ultralytics compatible model.  


This repo supports two types of neural network models:
1. .pt - better for development or in any case we have GPGPU
2. .onnx - better for CPU based platforms

The detectorTracker will handle them a little differently, but results should be very much the same.

*Note: Exporting a model to .onnx can be done in various ways.\
we currently support "simplified=True", and "uint8=False"

---
## usage

### â–¶ï¸ Running the System


Use the ***DetectorTracker*** object.

You can configure options using parameters:
- detector_model_file_path - path to detection deep learning model
- detection_frame_size - (image width, image height) for detection image
                                       image will automatically be resized or cropped to this size!
- detection_confidence_th - minimal confidence threshold for accepting object detection
- detector_use_cpu - force using CPU for detection even if GPU exists (used for timing tests)


Use \`detector_tracker_record_test.py\` to perform detection on an image library:

```bash
python detector_tracker_record_test.py
```


### ğŸ“Š Output

The ***DetectorTracker*** object outputs a list of tracks after each step.
Each track has: id, bbox, score


The \`detector_tracker_record_test.py\`:
- Real-time video display with bounding boxes and tracking IDs
- Optionally saves:
  - Processed video output (\`output.avi\`)



---

## ğŸ“Œ Use Cases

- Drone detection in restricted airspace
- Wildlife monitoring
- Surveillance and perimeter defense
- Air traffic visualization in simulations

---

## ğŸ§© Future Enhancements

- Integration with radar or GPS fusion
- Non-convex object filtering (using Shapely)
- Web dashboard for remote monitoring
- Support for 3D tracking with stereo or depth cameras

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information.

## ğŸ¤ Contributing

Contributions, ideas, and feedback are welcome! Please open issues or pull requests if you'd like to help improve this project.

## ğŸ“¬ Contact

For questions or support, feel free to reach out via [GitHub Issues](https://github.com/roee-lulav/deep_drone_detector/issues).
